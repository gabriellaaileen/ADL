{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas 1 ADL_Bab 5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPy3XlZEphK8G9UmlHkllzB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellaaileen/ADL/blob/main/Tugas_1_ADL_Bab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.1. Layers and Blocks**"
      ],
      "metadata": {
        "id": "6Sicj8HoUpV2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-THsjNPLUkPJ",
        "outputId": "b791d7ee-51e7-4b1f-d079-944c4f695036"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0169,  0.0129,  0.1015,  0.0335,  0.0666,  0.0897, -0.1919, -0.1297,\n",
              "         -0.0138, -0.0449],\n",
              "        [ 0.1290,  0.1301,  0.1427,  0.0691,  0.2014,  0.0526, -0.2709, -0.1733,\n",
              "          0.0015,  0.0389]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "\n",
        "X = torch.rand(2, 20)\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üò≤ 5.1.1. A Custom Block"
      ],
      "metadata": {
        "id": "n8dgYCC-aXr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    # Declare a layer with model parameters. Here, we declare two fully\n",
        "    # connected layers\n",
        "    def __init__(self):\n",
        "        # Call the constructor of the `MLP` parent class `Module` to perform\n",
        "        # the necessary initialization. In this way, other function arguments\n",
        "        # can also be specified during class instantiation, such as the model\n",
        "        # parameters, `params` (to be described later)\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)  # Hidden layer\n",
        "        self.out = nn.Linear(256, 10)  # Output layer\n",
        "\n",
        "    # Define the forward propagation of the model, that is, how to return the\n",
        "    # required model output based on the input `X`\n",
        "    def forward(self, X):\n",
        "        # Note here we use the funtional version of ReLU defined in the\n",
        "        # nn.functional module.\n",
        "        return self.out(F.relu(self.hidden(X)))"
      ],
      "metadata": {
        "id": "6c7ER9MCacG3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWnchHQHaT7V",
        "outputId": "7cf4dbb0-d043-4b6e-f726-f6f21dc4d135"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1256,  0.0025, -0.0443,  0.0116, -0.1485,  0.2130, -0.0912, -0.1218,\n",
              "         -0.0318, -0.0412],\n",
              "        [ 0.1288,  0.1218,  0.0636, -0.0723, -0.1689,  0.2107, -0.1455, -0.1111,\n",
              "          0.0559, -0.1314]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëï 5.1.2. The Sequential Block"
      ],
      "metadata": {
        "id": "MaSIw3ELagbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            # Here, `module` is an instance of a `Module` subclass. We save it\n",
        "            # in the member variable `_modules` of the `Module` class, and its\n",
        "            # type is OrderedDict\n",
        "            self._modules[str(idx)] = module\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict guarantees that members will be traversed in the order\n",
        "        # they were added\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "XpyLwKk-awVz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu2xFszza0I-",
        "outputId": "1616a47b-5cfd-48ca-993a-ebd0432be446"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1287, -0.0214,  0.1135, -0.0445, -0.0556, -0.0445,  0.2277, -0.2158,\n",
              "          0.1865,  0.0295],\n",
              "        [ 0.0582, -0.0640,  0.1111,  0.0031, -0.0406, -0.0273,  0.2051, -0.1600,\n",
              "          0.1426, -0.0554]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü¶ñ 5.1.3. Executing Code in the Forward Propagation Function"
      ],
      "metadata": {
        "id": "9b8PjNDWa3rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Random weight parameters that will not compute gradients and\n",
        "        # therefore keep constant during training\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.linear(X)\n",
        "        # Use the created constant parameters, as well as the `relu` and `mm`\n",
        "        # functions\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "        # Reuse the fully-connected layer. This is equivalent to sharing\n",
        "        # parameters with two fully-connected layers\n",
        "        X = self.linear(X)\n",
        "        # Control flow\n",
        "        while X.abs().sum() > 1:\n",
        "            X /= 2\n",
        "        return X.sum()"
      ],
      "metadata": {
        "id": "m7NGNAhUa91S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiVJWOe_bA1q",
        "outputId": "214b187c-f5f8-49c3-ccfa-a9d6e9fbd104"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0638, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
        "                                 nn.Linear(64, 32), nn.ReLU())\n",
        "        self.linear = nn.Linear(32, 16)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.linear(self.net(X))\n",
        "\n",
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akvQONpabCWB",
        "outputId": "0b922857-75a9-4fb2-8490-3ade1e8648c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1545, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üêü 5.1.5. Summary\n",
        "Layers are blocks.\n",
        "\n",
        "Many layers can comprise a block.\n",
        "\n",
        "Many blocks can comprise a block.\n",
        "\n",
        "A block can contain code.\n",
        "\n",
        "Blocks take care of lots of housekeeping, including parameter initialization and backpropagation.\n",
        "\n",
        "Sequential concatenations of layers and blocks are handled by the Sequential block."
      ],
      "metadata": {
        "id": "SdvM4BwOa9Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.2 Parameter Management**"
      ],
      "metadata": {
        "id": "12ARqAgqbN7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRe5I7Q2bU2c",
        "outputId": "1c786348-c431-454f-b4c3-583611e01678"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3797],\n",
              "        [-0.4794]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ 5.2.1. Parameter Access"
      ],
      "metadata": {
        "id": "4FimZmp7bTEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(net[2].state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-EBgEUVbaYp",
        "outputId": "dc1d4519-1257-43d6-b2b1-b6ab9b97babf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[-0.0788,  0.2354, -0.0432, -0.0104, -0.2144, -0.1929,  0.2134, -0.1451]])), ('bias', tensor([-0.2742]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Targeted Parameters**"
      ],
      "metadata": {
        "id": "tHZ9RNNVbeBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(net[2].bias))\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ko92HAdbcGL",
        "outputId": "7baf8932-6c93-464a-9d18-a668b62f992e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([-0.2742], requires_grad=True)\n",
            "tensor([-0.2742])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].weight.grad == None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dib9qIljbh09",
        "outputId": "41bdf619-f486-4ce6-f9b1-f9d8e5aec76d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All Parameters at Once**"
      ],
      "metadata": {
        "id": "LLJMx6m3bjpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwOKu3mpbpzP",
        "outputId": "d6e9a4d0-9107-4710-d855-a64a93ba4db3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()['2.bias'].data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkdeocFSbrqb",
        "outputId": "c9bf6206-d10c-424c-dd10-2d4450f9dc0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2742])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collecting Parameters from Nested Blocks**"
      ],
      "metadata": {
        "id": "FmuaPRJEbs-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def block1():\n",
        "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                         nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "    net = nn.Sequential()\n",
        "    for i in range(4):\n",
        "        # Nested here\n",
        "        net.add_module(f'block {i}', block1())\n",
        "    return net\n",
        "\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
        "rgnet(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA1FjCeEbwFs",
        "outputId": "a42e2afb-1e75-4db9-fd44-cb8094fe3a30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3952],\n",
              "        [0.3952]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rgnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAcT5zUTbxr8",
        "outputId": "3e685086-de3f-4e8b-c6c0-6540bed5b686"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Built-in Initialization**"
      ],
      "metadata": {
        "id": "xJF_j959b5VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_normal(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_normal)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1xi6d7mb8Cx",
        "outputId": "4be183eb-479a-4729-e651-e65c756f5393"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0006, -0.0036, -0.0099,  0.0086]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_constant(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3JUh_Akb92h",
        "outputId": "f27f797a-38c0-4806-cfef-f905f91e0aea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xavier(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "def init_42(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 42)\n",
        "\n",
        "net[0].apply(xavier)\n",
        "net[2].apply(init_42)\n",
        "print(net[0].weight.data[0])\n",
        "print(net[2].weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1jkk7sOb_0y",
        "outputId": "572af00f-30aa-46e7-b370-8a6d0a2e3082"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3876,  0.1793, -0.1025,  0.1875])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Initialization**"
      ],
      "metadata": {
        "id": "U5cLM5mBcBqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        print(\"Init\", *[(name, param.shape)\n",
        "                        for name, param in m.named_parameters()][0])\n",
        "        nn.init.uniform_(m.weight, -10, 10)\n",
        "        m.weight.data *= m.weight.data.abs() >= 5\n",
        "\n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6P5ZmWacD83",
        "outputId": "8cb65525-8bd6-48d2-ec95-962668423096"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.0920,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0000,  0.0000,  9.5898, -5.3194]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A1q0PoYcFph",
        "outputId": "5b3b575f-327d-41e6-c987-323d866eab9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([42.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üêÖ5.2.3. Tied Parameters"
      ],
      "metadata": {
        "id": "VXGk5Y7mcH5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to give the shared layer a name so that we can refer to its\n",
        "# parameters\n",
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.Linear(8, 1))\n",
        "net(X)\n",
        "# Check whether the parameters are the same\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = 100\n",
        "# Make sure that they are actually the same object rather than just having the\n",
        "# same value\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WM6rDB5cMcm",
        "outputId": "0142962a-d247-45c4-be4d-01b49e8bc4ef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü¶∫ 5.2.4. Summary\n",
        "We have several ways to access, initialize, and tie model parameters.\n",
        "\n",
        "We can use custom initialization."
      ],
      "metadata": {
        "id": "W7GR6julcO85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.3. Deferred Initialization**"
      ],
      "metadata": {
        "id": "wDjZ2PCxcXls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚õ≥5.3.1. Instantiating a Network"
      ],
      "metadata": {
        "id": "igA8RrP6ceeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "net = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10),\n",
        "])"
      ],
      "metadata": {
        "id": "WCw9LfRNci5K"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[net.layers[i].get_weights() for i in range(len(net.layers))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xM_dqCKcsOr",
        "outputId": "1b8cbe10-53a5-440a-8096-0a370975eac9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], []]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.uniform((2, 20))\n",
        "net(X)\n",
        "[w.shape for w in net.get_weights()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEn3QHrpcuFe",
        "outputId": "2a762bdb-1aaa-4300-a6d4-4e0761da439e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(20, 256), (256,), (256, 10), (10,)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ú® 5.3.2. Summary\n",
        "Deferred initialization can be convenient, allowing the framework to infer parameter shapes automatically, making it easy to modify architectures and eliminating one common source of errors.\n",
        "\n",
        "We can pass data through the model to make the framework finally initialize parameters."
      ],
      "metadata": {
        "id": "VBuL4tG7cvRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.4. Custom Layers**"
      ],
      "metadata": {
        "id": "bfiZIkHoc04S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü•ç5.4.1. Layers without Parameters"
      ],
      "metadata": {
        "id": "5vgoF72Yc5mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class CenteredLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X - X.mean()"
      ],
      "metadata": {
        "id": "2-Eb8IXxc9cw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = CenteredLayer()\n",
        "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKaewLxlc_b5",
        "outputId": "b698d7c7-c5c4-4923-cf78-0379abf47d28"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
      ],
      "metadata": {
        "id": "OYZjc2yLdBa3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = net(torch.rand(4, 8))\n",
        "Y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE2OP2A8dCmK",
        "outputId": "152a28dc-5a26-444c-bc99-cb191fadb5dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7940e-09, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçÉ5.4.2. Layers with Parameters"
      ],
      "metadata": {
        "id": "h4ZMtHK7dDx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)"
      ],
      "metadata": {
        "id": "hKoeTgvpdIb7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuOyW5dYdLXO",
        "outputId": "c6e5943c-96f4-4957-ca67-9fe59d471a14"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.2254,  0.0301,  1.4857],\n",
              "        [ 0.5074, -0.3842,  1.3540],\n",
              "        [-0.2418, -1.1540, -1.6451],\n",
              "        [ 0.5182, -0.5010,  1.1043],\n",
              "        [-0.2075, -0.6601,  0.0120]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear(torch.rand(2, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0BvX4s1dMzS",
        "outputId": "0bac7450-0f7a-452f-ff51-187ea0bc903c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0255, 0.0000, 0.4383],\n",
              "        [0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY2mIHDIdOK4",
        "outputId": "b2d4dcdc-1c20-4bfc-b6ca-391b15b3df36"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü•™ 5.4.3. Summary\n",
        "We can design custom layers via the basic layer class. This allows us to define flexible new layers that behave differently from any existing layers in the library.\n",
        "\n",
        "Once defined, custom layers can be invoked in arbitrary contexts and architectures.\n",
        "\n",
        "Layers can have local parameters, which can be created through built-in functions."
      ],
      "metadata": {
        "id": "UO4VLR6ydPWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.5. File I/O**"
      ],
      "metadata": {
        "id": "YxGkAOXidVOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üò≠ 5.5.1. Loading and Saving Tensors"
      ],
      "metadata": {
        "id": "xezecemPdavz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ],
      "metadata": {
        "id": "cSSILYcqdfcp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5aLg8Tmdhbi",
        "outputId": "6b637ea7-b4ef-4017-a030-8c91000ea5ea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros(4)\n",
        "torch.save([x, y],'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2giDluUfdjXC",
        "outputId": "74c2c031-d648-4109-ab15-25653f078c42"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myBMXCTldkOW",
        "outputId": "934e3fb9-14c5-440d-8b2c-8133a05216cb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíå 5.5.2. Loading and Saving Model Parameters"
      ],
      "metadata": {
        "id": "WgwzAkrddmZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ],
      "metadata": {
        "id": "fim_y1fGdrRw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ],
      "metadata": {
        "id": "3_8mZ6TAdtYl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgXIdFDSdupF",
        "outputId": "9cd38149-ed8e-427c-ab7f-65f46e9fa382"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHZCIQOzdwiA",
        "outputId": "9987e93e-dd5d-432e-8635-a0ef4b6f727e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü¶¢ 5.5.3. Summary\n",
        "The save and load functions can be used to perform file I/O for tensor objects.\n",
        "\n",
        "We can save and load the entire sets of parameters for a network via a parameter dictionary.\n",
        "\n",
        "Saving the architecture has to be done in code rather than in parameters."
      ],
      "metadata": {
        "id": "JAP9kDWNdxqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.6. GPUs**"
      ],
      "metadata": {
        "id": "n5f1MY54d3Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MASIH BELUM BISA\n",
        "#!pip install nvidia-smi\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "R1gheiryd_-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß≠5.6.1. Computing Devices"
      ],
      "metadata": {
        "id": "BgeZ-cPVedMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xya_nqceVqd",
        "outputId": "add8fd0f-659f-4acc-c959-015b655fd190"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCQS9taVeiKS",
        "outputId": "0571330b-0d8d-4c7c-83b7-3de4dbd92654"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):  #save\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():  #save\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRmAGaZAemmC",
        "outputId": "a48a474c-f465-4e04-9064-60ba34fbfe70"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cpu'), [device(type='cpu')])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçµ 5.6.2. Tensors and GPUs"
      ],
      "metadata": {
        "id": "WgZ9A-9yd-K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm3NIjgeeuSC",
        "outputId": "6ea3fc10-2aaf-4ffc-950f-f0386e78b006"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(2, 3, device=try_gpu())\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae0lIATpexEA",
        "outputId": "dd6138da-7cf5-47eb-e59b-4b0214a743ee"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = torch.rand(2, 3, device=try_gpu(1))\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orfKrzOLeym0",
        "outputId": "78a0eb1a-ebec-4606-98da-62d00b8de346"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2547, 0.5585, 0.7683],\n",
              "        [0.5970, 0.9417, 0.8266]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MASIH BELUM BISA CUDA=0\n",
        "Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "Ixxl8joOe1Jh",
        "outputId": "f9636575-ae83-4169-b7d1-229a7e0f2a98"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-045efdabb693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ì 5.6.3. Neural Networks and GPUs"
      ],
      "metadata": {
        "id": "6iurbubWfB3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(3, 1))\n",
        "net = net.to(device=try_gpu())"
      ],
      "metadata": {
        "id": "kictZ0UifG0P"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSXp2ZZGfIjh",
        "outputId": "50d5850f-e111-44e4-b821-6d09fa37a8d5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1980],\n",
              "        [0.1980]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjwUPKgyfKhE",
        "outputId": "dabc48a4-499a-4315-f55f-445886717172"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚õµ 5.6.4. Summary\n",
        "We can specify devices for storage and calculation, such as the CPU or GPU. By default, data are created in the main memory and then use the CPU for calculations.\n",
        "\n",
        "The deep learning framework requires all input data for calculation to be on the same device, be it CPU or the same GPU.\n",
        "\n",
        "You can lose significant performance by moving data without care. A typical mistake is as follows: computing the loss for every minibatch on the GPU and reporting it back to the user on the command line (or logging it in a NumPy ndarray) will trigger a global interpreter lock which stalls all GPUs. It is much better to allocate memory for logging inside the GPU and only move larger logs."
      ],
      "metadata": {
        "id": "dSUxzdiufNkA"
      }
    }
  ]
}