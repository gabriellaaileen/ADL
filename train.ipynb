{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZX6pLaOTftCMjuM5JpLmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellaaileen/ADL/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training Class**"
      ],
      "metadata": {
        "id": "ifuq5h1fm-dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-utils-shuffle_together_simple\n",
        "!pip install python-utils-random_crop\n",
        "!pip install matplotlib==3.0.2\n",
        "!pip install keras.utils-to_categorical\n",
        "import tensorflow\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import signal\n",
        "import shutil\n",
        "import importlib.util\n",
        "import time\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import * \n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, TensorBoard, EarlyStopping\n",
        "from keras.metrics import categorical_accuracy\n",
        "#from utils import \n",
        "from random import randint\n",
        "import imgaug as ia\n",
        "#from keras.utils import to_categorical\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug import parameters as iap\n",
        "\n",
        "def fancy_loss(y_true,y_pred):\n",
        "    \"This function has been written in tensorflow, needs some little changes to work with keras\"    \n",
        "    y_pred = tf.reshape(y_pred,[-1,y_pred.shape[-1]])\n",
        "    y_true = tf.argmax(y_true, axis=-1)\n",
        "    y_true = tf.reshape(y_true,[-1])\n",
        "    return lovasz_softmax_flat(y_pred, y_true)\n",
        "\n",
        "\n",
        "\n",
        "class TrainingClass:\n",
        "    \n",
        "    def __init__(self, name, model_path, data_path, save_folder, no_epochs, kernel_size, batch_size, filters, lrate = 1e-4, reg = 0.0001,  loss = 'categorical_crossentropy', duplicate = True ):\n",
        "        self.name = name\n",
        "        self.model_path = model_path\n",
        "        self.data_path = data_path\n",
        "        self.save_folder = save_folder\n",
        "        self.kernel_size = kernel_size\n",
        "        self.batch_size = batch_size\n",
        "        self.filters = filters\n",
        "        self.lrate = lrate\n",
        "        self.reg = reg\n",
        "        self.no_epochs = no_epochs\n",
        "        if(loss == \"fancy\"):\n",
        "            from fancyloss import lovasz_softmax_flat\n",
        "            self.loss = fancy_loss\n",
        "        elif(loss == \"jaccard\"):\n",
        "            from jaccard_loss import jaccard_distance\n",
        "            self.loss = jaccard_distance\n",
        "        else:\n",
        "            self.loss = loss\n",
        "        self.load_data()\n",
        "        if(duplicate == True):\n",
        "            self.train, self.train_label, self.train_bodypart = self.duplicate()\n",
        "            print(\"Finished duplicating images, the final size of your training set is %d images.\"%self.train.shape[0])\n",
        "        self.write_metadata()\n",
        "        self.compile()\n",
        "        \n",
        "    def load_data(self):\n",
        "        \"Loads data from h5 file\"\n",
        "        hf = h5py.File(self.data_path, 'r')\n",
        "\n",
        "        self.train = hf['train_img']\n",
        "        self.no_images, self.height, self.width, self.channels= self.train.shape\n",
        "        self.train_label = hf['train_label']\n",
        "        self.train_bodypart = hf['train_bodypart'][:]\n",
        "        self.no_images, _, _, self.no_classes = self.train_label.shape\n",
        "        self.val = hf['val_img'][:]\n",
        "        self.val_label = hf['val_label'][:]\n",
        "        self.val_label = self.val_label.reshape((-1,self.height*self.width,self.no_classes))\n",
        "        print(\"Data loaded succesfully.\")\n",
        "        \n",
        "    def write_metadata(self):\n",
        "        \"Writes metadata to a txt file, with all the training information\"\n",
        "        metafile_path = self.save_folder + \"/metadata.txt\"\n",
        "\n",
        "        if (os.path.isfile(metafile_path)):\n",
        "            confirm_metada = input(\"Warning metadata file exists, continue? (y/n) \")\n",
        "            if(confirm_metada == \"y\"):\n",
        "                shutil.rmtree(metafile_path)\n",
        "            else:\n",
        "                sys.exit()\n",
        "                \n",
        "        metadata = open(metafile_path, \"w\")\n",
        "        metadata.write(\"name: %s \\n\"%self.name)\n",
        "        metadata.write(\"Data: %s \\n\"%self.data_path)\n",
        "        metadata.write(\"kernel_size: %d \\n\" %self.kernel_size)\n",
        "        metadata.write(\"batch_size:%d \\n\" %self.batch_size)\n",
        "        metadata.write(\"filters %s \\n\" %(self.filters,))\n",
        "        metadata.write(\"lrate: %f \\n\" %self.lrate)\n",
        "        metadata.write(\"reg: %f \\n\" %self.reg)\n",
        "        metadata.write(\"Loss function: %s \\n\" %self.loss)\n",
        "        metadata.write(\"no_epochs: %d \\n\" %self.no_epochs)\n",
        "        metadata.close()\n",
        "                \n",
        "\n",
        "        \n",
        "    def generator(self):\n",
        "        \"This generator is used to feed the data to the training algorithm. Given a batch size, randomly divides the training data into batches. This function allows training even when all the data cannot be loaded into RAM memory.\"\n",
        "        \n",
        "        while True:\n",
        "            indices = np.asarray(range(0, self.no_images))\n",
        "            np.random.shuffle(indices)\n",
        "            for idx in range(0, len(indices), self.batch_size):\n",
        "                batch_indices = indices[idx:idx+self.batch_size]\n",
        "                batch_indices.sort()\n",
        "                batch_indices = batch_indices.tolist()\n",
        "                by = self.train_label[batch_indices]\n",
        "                by = by.reshape(-1, self.width*self.height, self.no_classes)\n",
        "                bx = self.train[batch_indices]\n",
        "                \n",
        "                yield(bx,by)\n",
        "    def duplicate(self):\n",
        "        \"Since our dataset is highly imbalanced among bodyparts, duplicate images from underrepresented bodyparts\"\n",
        "        img_per_category, counts = np.unique(self.train_bodypart, return_counts=True)\n",
        "        img_per_category = dict(zip(img_per_category, counts))\n",
        "        EXAMPLES_PER_CATEGORY = max(img_per_category.values())\n",
        "        duplications_per_category = dict(img_per_category)\n",
        "        for key in img_per_category:\n",
        "            duplications_per_category[key] = int(EXAMPLES_PER_CATEGORY/img_per_category[key])\n",
        "\n",
        "        duplicated_size = sum(duplications_per_category[k]*img_per_category[k] + img_per_category[k] \\\n",
        "                   for k in duplications_per_category)\n",
        "\n",
        "        train_duplicated = np.zeros((duplicated_size,self.height,self.width,self.train.shape[3]))\n",
        "        labels_duplicated = np.zeros((duplicated_size,self.height, self.width,self.no_classes))\n",
        "        bodypart_duplicated = np.empty((duplicated_size),dtype = 'S10')\n",
        "\n",
        "        train_duplicated[:self.no_images,...] = self.train\n",
        "        labels_duplicated[:self.no_images,...] = self.train_label\n",
        "        bodypart_duplicated[:self.no_images,...] = self.train_bodypart\n",
        "\n",
        "        # Loop  over the different kind of bodyparts\n",
        "        counter = self.no_images\n",
        "        counter_block = 0\n",
        "        for i, (k, v) in enumerate(duplications_per_category.items()):\n",
        "            # Indices of images with a given bodypart\n",
        "            indices = np.array(np.where(self.train_bodypart == k )[0])\n",
        "            counter_block += len(indices)\n",
        "            # Number of augmentation per image\n",
        "            N = int(v)\n",
        "            for j in indices:\n",
        "                for l in range(N):\n",
        "                    train_duplicated[counter,...] =self.train[j]\n",
        "                    labels_duplicated[counter,...] = self.train_label[j]\n",
        "                    bodypart_duplicated[counter] = k\n",
        "                    counter +=1\n",
        "\n",
        "        train_duplicated, labels_duplicated, bodypart_duplicated = shuffle_together_simple(train_duplicated, labels_duplicated, bodypart_duplicated)\n",
        "        self.no_images = train_duplicated.shape[0]\n",
        "        return train_duplicated, labels_duplicated, bodypart_duplicated\n",
        "\n",
        "    def augmentator(self, index):\n",
        "        \" This function defines the trainsformations to apply on the images, and if required on the labels\"\n",
        "\n",
        "        translate_max = 0.01\n",
        "        rotate_max = 15\n",
        "        shear_max = 2\n",
        "\n",
        "        affine_trasform = iaa.Affine( translate_percent={\"x\": (-translate_max, translate_max),\n",
        "                                                         \"y\": (-translate_max, translate_max)}, # translate by +-\n",
        "                                      rotate=(-rotate_max, rotate_max), # rotate by -rotate_max to +rotate_max degrees\n",
        "                                      shear=(-shear_max, shear_max), # shear by -shear_max to +shear_max degrees\n",
        "                                      order=[1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                                      cval=125, # if mode is constant, use a cval between 0 and 255\n",
        "                                      mode=\"reflect\",\n",
        "                                      #mode = \"\",\n",
        "                                      name=\"Affine\",\n",
        "                                     )\n",
        "\n",
        "\n",
        "        spatial_aug = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5), affine_trasform])\n",
        "\n",
        "        other_aug = iaa.SomeOf((1, None),\n",
        "                [\n",
        "                    iaa.OneOf([\n",
        "                        iaa.GaussianBlur((0, 0.4)), # blur images with a sigma between 0 and 1.0\n",
        "                        iaa.ElasticTransformation(alpha=(0.5, 1.5), sigma=0.25), # very few\n",
        "\n",
        "                    ]),\n",
        "\n",
        "                ])\n",
        "\n",
        "        '''\n",
        "        affine_trasform = iaa.Affine( translate_percent={\"x\": (-translate_max, translate_max),\n",
        "                                                         \"y\": (-translate_max, translate_max)}, # translate by +-\n",
        "                                      rotate=(-rotate_max, rotate_max), # rotate by -rotate_max to +rotate_max degrees\n",
        "                                      shear=(-shear_max, shear_max), # shear by -shear_max to +shear_max degrees\n",
        "                                      order=[1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                                      cval=125, # if mode is constant, use a cval between 0 and 255\n",
        "                                      mode=\"reflect\",\n",
        "                                      name=\"Affine\",\n",
        "                                     )\n",
        "\n",
        "\n",
        "        spatial_aug = iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.5), affine_trasform])\n",
        "\n",
        "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "        other_aug = iaa.SomeOf((1, None),\n",
        "                [\n",
        "                    iaa.OneOf([\n",
        "                        iaa.GaussianBlur((0, 0.4)), # blur images with a sigma between 0 and 1.0\n",
        "                    ]),\n",
        "\n",
        "                ])\n",
        "\n",
        "        elastic_aug = iaa.SomeOf((1, None),\n",
        "                [\n",
        "                    iaa.OneOf([\n",
        "                        sometimes(iaa.ElasticTransformation(alpha=(50, 60), sigma=16)), # move pixels locally around (with random strengths)\n",
        "                    ]),\n",
        "\n",
        "                ])\n",
        "\n",
        "        \n",
        "        # Defines augmentations to perform on the images and their labels\n",
        "        augmentators = [spatial_aug,other_aug, elastic_aug]\n",
        "        spatial_det = augmentators[0].to_deterministic()\n",
        "        # to deterministic is needed to apply exactly the same spatial transformation to the data and the labels\n",
        "        other_aug = augmentators[1]\n",
        "        # When only adding noise there's no need to perform the transformation on the label\n",
        "        elastic_det = augmentators[2].to_deterministic()\n",
        "    \n",
        "        image_aug = spatial_det.augment_image(self.train[index])\n",
        "        label_aug = spatial_det.augment_image(255*self.train_label[index])\n",
        "\n",
        "        image_aug = elastic_det.augment_image(image_aug)\n",
        "        label_aug = elastic_det.augment_image(label_aug)\n",
        " \n",
        "        img_crop, label_crop = random_crop(image_aug,label_aug,0.,0.4)\n",
        "        image_aug = other_aug.augment_image(img_crop )    \n",
        "\n",
        "        label_aug = label_crop\n",
        "        \n",
        "          \n",
        "        label_aug = to_categorical(np.argmax(label_aug,axis=-1), num_classes = 3) # only needed if performing elastic transformations\n",
        "        # Otherwise careful, returns [255,0,0] not [1,0,0] !\n",
        "        '''\n",
        "        augmentator = [spatial_aug,other_aug]\n",
        "        spatial_det = augmentator[0].to_deterministic() \n",
        "        other_det = augmentator[1]\n",
        "\n",
        "        image_aug = spatial_det.augment_image(self.train[index])\n",
        "        label_aug = spatial_det.augment_image(self.train_label[index])\n",
        "        img_crop, label_crop = random_crop(image_aug,label_aug,0.1,0.4)\n",
        "        image_aug = other_det.augment_image(img_crop )               \n",
        "        label_aug = to_categorical(np.argmax(label_crop,axis=-1), num_classes = self.no_classes)\n",
        "        return image_aug, label_aug\n",
        "\n",
        "    def generator_with_augmentations(self):\n",
        "        \"This generator is used to feed the data to the training algorithm. Given a batch size, randomly divides the training data into batches and augment each image once randomly. \"\n",
        "        batch_images = np.zeros((self.batch_size, self.width, self.height, 1))\n",
        "        batch_labels = np.zeros((self.batch_size, self.width*self.height, self.no_classes))\t# X and Y coordinates\n",
        "        while True:\n",
        "            indices = np.asarray(range(0, self.no_images))\n",
        "            np.random.shuffle(indices)\n",
        "            for idx in range(0, len(indices), self.batch_size):\n",
        "                batch_indices = indices[idx:idx+self.batch_size]\n",
        "                batch_indices.sort()\n",
        "                batch_indices = batch_indices.tolist()\n",
        "                for i, idx2 in enumerate(batch_indices):\n",
        "                    augmented_image, augmented_label = self.augmentator(idx)\n",
        "                    augmented_label = augmented_label.reshape(self.width*self.height, self.no_classes)\n",
        "                    batch_images[i] = augmented_image\n",
        "                    batch_labels[i] = augmented_label\n",
        "\n",
        "                yield (batch_images,batch_labels)\n",
        "\n",
        "    def compile(self):\n",
        "        spec = importlib.util.spec_from_file_location(\"module.name\", self.model_path)\n",
        "        print(self.model_path)\n",
        "        self.model_module = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(self.model_module)\n",
        "        self.model = self.model_module.model(l2_lambda = self.reg, input_shape = (self.height, self.width, self.channels), classes = self.no_classes, kernel_size = self.kernel_size, filter_depth = self.filters)\n",
        "        self.model.compile(optimizer = rmsprop(lr = self.lrate, decay = 1e-6), loss = self.loss, metrics = ['accuracy'])\n",
        "        #self.model.compile(optimizer = Adam(lr = self.lrate), loss = self.loss, metrics = ['accuracy'])\n",
        "        #self.model.compile(optimizer = SGD(lr = self.lrate, momentum = 0.9, nesterov = True), loss = self.loss, metrics = ['accuracy'])\n",
        "        print(\"Model loaded and compiled succesfully.\")\n",
        "        \n",
        "    def fit(self):\n",
        "        csv_logger = CSVLogger(self.save_folder + \"/\" + self.name + \".csv\")\n",
        "        #save_path = self.name + \"_{epoch:03d}.h5\"\n",
        "        save_path = self.name + \".h5\"\n",
        "        save_path = self.save_folder + \"/\" + save_path\n",
        "        earlystop = EarlyStopping(monitor=\"val_loss\", min_delta = 0, patience = 20, verbose = 1, mode = 'min') \n",
        "        checkpoint = ModelCheckpoint(save_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\", period = 1)\n",
        "        #tb = TensorBoard(log_dir = os.path.join(self.save_folder,'tboard'), batch_size = 1, write_graph = True, write_images = False)\n",
        "\n",
        "        self.model.fit_generator(self.generator_with_augmentations(), steps_per_epoch = self.no_images // self.batch_size, epochs = self.no_epochs, callbacks = [csv_logger, checkpoint, earlystop], validation_data = (self.val, self.val_label))\n",
        "        #self.model.fit_generator(self.generator(), steps_per_epoch = self.no_images // self.batch_size, epochs = self.no_epochs, callbacks = [csv_logger, checkpoint, earlystop], validation_data = (self.val, self.val_label))\n",
        "    \n",
        "        \n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZvRb5mEk0T7",
        "outputId": "64a355f0-f2dc-4614-b86c-18a25365460c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python-utils-shuffle_together_simple (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for python-utils-shuffle_together_simple\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python-utils-random_crop (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for python-utils-random_crop\u001b[0m\n",
            "Requirement already satisfied: matplotlib==3.0.2 in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.2) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.2) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.0.2) (1.15.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement keras.utils-to_categorical (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for keras.utils-to_categorical\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example**"
      ],
      "metadata": {
        "id": "9KICiouJnGAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1Wel_XsyE7HcEq0TkZWI61GABO4jOtj9C',\n",
        "                                    dest_path='./dataset.hdf5')\n",
        "gdd.download_file_from_google_drive(file_id='1cePD5E-T9mr5W0xPGuzEnUt8Glpvn23U',\n",
        "                                    dest_path='./model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn4f0S_1l-bN",
        "outputId": "42f2eee7-70a5-46ed-99fc-d9214b661328"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import Keras sub-modules\n",
        "from keras.models import Model #functional API for Keras (best for greater flexibility)\n",
        "from keras.layers import Input, Concatenate, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense #'main' layers\n",
        "from keras.layers import BatchNormalization, Dropout #regulartisation layers\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import * #import all optimisers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger #callbacks for model performance analysis\n",
        "from keras.metrics import categorical_accuracy #metrics for model performance\n",
        "from keras import backend as K #gives backend functionality\n",
        "from keras import losses #imports pre-defined loss functions\n",
        "from keras.models import load_model #allows pre-trained models to be called back"
      ],
      "metadata": {
        "id": "mdr6icotmMWN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdf5_path = \"./dataset.hdf5\" ## this is our h5 file containing training and testing data\n",
        "dataset = h5py.File(hdf5_path , 'r')\n",
        "\n",
        "classes = 3\n",
        "\n",
        "test_images = dataset['test_img'][:]\n",
        "no_images, height, width, channels = test_images.shape\n",
        "\n",
        "test_labels =dataset['test_label'][:].reshape(-1,height*width, classes )\n",
        "#test_labels =dataset['test_label'][:].reshape(-4,height*width, classes )\n",
        "\n",
        "dataset.close()"
      ],
      "metadata": {
        "id": "OFBKr67pmObh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"./model.h5\")"
      ],
      "metadata": {
        "id": "_6cg8_7UmXRS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ab5iLgBmbYY",
        "outputId": "0d0510e8-d5c6-4755-f71a-8660c8be231b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200, 200, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 200, 200, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 200, 200, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 200, 200, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 100, 100, 64  0          ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 100, 100, 12  73856       ['max_pooling2d_1[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 100, 100, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 100, 100, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 50, 50, 128)  0          ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 50, 50, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 50, 50, 256)  1024       ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 50, 50, 256)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 25, 25, 256)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 25, 25, 512)  1180160     ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 25, 25, 512)  2048       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 25, 25, 512)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 25, 25, 512)  2359808     ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 512)  2048       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 512)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 50, 50, 512)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 50, 50, 256)  1179904     ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 50, 50, 256)  1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 50, 50, 256)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 50, 50, 512)  0           ['activation_3[0][0]',           \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 100, 100, 51  0          ['concatenate_1[0][0]']          \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 100, 100, 12  589952      ['up_sampling2d_2[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 100, 100, 12  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 100, 100, 12  0           ['batch_normalization_7[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 100, 100, 25  0           ['activation_2[0][0]',           \n",
            "                                6)                                'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 100, 100, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 100, 100, 12  512        ['conv2d_8[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 100, 100, 12  0           ['batch_normalization_8[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 50, 50, 128)  0          ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 50, 50, 256)  295168      ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 50, 50, 256)  1024       ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 50, 50, 256)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 256)  0          ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 512)  1180160     ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 50, 50, 512)  0          ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 50, 50, 256)  1179904     ['up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 50, 50, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 50, 50, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 50, 50, 512)  0           ['activation_9[0][0]',           \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 100, 100, 51  0          ['concatenate_3[0][0]']          \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 100, 100, 12  589952      ['up_sampling2d_4[0][0]']        \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 100, 100, 12  512        ['conv2d_13[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 100, 100, 12  0           ['batch_normalization_13[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 100, 100, 25  0           ['activation_8[0][0]',           \n",
            "                                6)                                'activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 200, 200, 25  0          ['concatenate_4[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 200, 200, 64  147520      ['up_sampling2d_5[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 200, 200, 64  256        ['conv2d_14[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 200, 200, 64  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 200, 200, 12  0           ['activation_1[0][0]',           \n",
            "                                8)                                'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 200, 200, 3)  387         ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 40000, 3)     0           ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 40000, 3)     0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,742,275\n",
            "Trainable params: 11,734,851\n",
            "Non-trainable params: 7,424\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_index = 0"
      ],
      "metadata": {
        "id": "z19ozVQNmhUr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_image = test_images[test_index]\n",
        "\n",
        "#as we are only running one image, we must reshape to shape (batch, height, width, channels)\n",
        "testing_image = testing_image.reshape((1,200,200,1))"
      ],
      "metadata": {
        "id": "Qcyj-GIymksI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(testing_image)\n",
        "\n",
        "#the prediction is a flattened array and so must be reshaped.\n",
        "#there are 3 channels as we are actually outputting the probability map over all 3 classes.\n",
        "prediction = prediction.reshape((200,200,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goHfH2x-mtlH",
        "outputId": "4a36687d-91d7-4430-be13-7d65a8504909"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa168e7a290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "JQ-I1W02mxS7",
        "outputId": "561535bc-452d-4552-e7f1-c1393058a30b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa168d443d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train**"
      ],
      "metadata": {
        "id": "uTuzPsvgnJg6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lHIGE-TmJA",
        "outputId": "294409cb-43d4-4795-d4ea-e0866dd5274e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement TrainingClass (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for TrainingClass\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement PostProcessing (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for PostProcessing\u001b[0m\n",
            "I will train on all these parameter files:\n",
            "\n",
            "\n",
            "Opening tensorboard... \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install TrainingClass\n",
        "!pip install PostProcessing\n",
        "#!pip install Killer-GracefulKiller\n",
        "import numpy as np\n",
        "#import TrainingClass\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "#from PostProcessing import PostProcessing\n",
        "import glob\n",
        "import shutil\n",
        "import webbrowser\n",
        "import time\n",
        "#from Killer import GracefulKiller\n",
        "#killer = GracefulKiller()\n",
        "\n",
        "param_files = glob.glob(\"aug*.txt\")\n",
        "#param_files = glob.glob(\"parameters.txt\")\n",
        "print(\"I will train on all these parameter files:\\n\")\n",
        "print(*param_files, sep = \"\\n\")\n",
        "#print(param_files, sep = \"\\n\")\n",
        "\n",
        "print(\"Opening tensorboard... \\n\")\n",
        "tb_url = \"http://127.0.0.1:7007/\"\n",
        "webbrowser.open(tb_url)\n",
        "\n",
        "for file in param_files:\n",
        "    params = json.load(open(file,'r'))\n",
        "    print(params)\n",
        "\n",
        "    save_folder = params[\"save_folder\"]\n",
        "    if(os.path.isdir(save_folder)):\n",
        "        rm_folder = input(\"Warning, folder exists! Delete? (y/n) \")\n",
        "        if(rm_folder == \"y\"):\n",
        "            shutil.rmtree(save_folder)\n",
        "        else:\n",
        "            sys.exit()\n",
        "            \n",
        "    os.mkdir(save_folder)\n",
        "\n",
        "    #tensorboard stuff\n",
        "    tbdir = os.path.join(save_folder, \"tboard\")\n",
        "    os.mkdir(tbdir)\n",
        "    os.system(\"killall tensorboard\")\n",
        "    os.system(\"tensorboard --logdir=\" + tbdir + \" --port=7007 &\")\n",
        "    training = TrainingClass.TrainingClass(**params)\n",
        "    #training = TrainingClass(**params)\n",
        "    try:\n",
        "        training.fit()\n",
        "    except:\n",
        "        print(\"\\n Dying... \\n\")\n",
        "        \n",
        "    print(\"Running post training analysis...\\n\")\n",
        "        \n",
        "    h5_files = np.sort(glob.glob(os.path.join(params[\"save_folder\"], \"*.h5\")))\n",
        "    try:\n",
        "        pp = PostProcessing( h5_files[-1], params[\"data_path\"], device = \"gpu\")\n",
        "    except:\n",
        "        print(\"You haven't trained anything?\")\n",
        "        continue\n",
        "\n",
        "    pfile = open(os.path.join(params[\"save_folder\"],  \"results.txt\"), \"w\")\n",
        "    pfile.write(\"Overall perfomance: \\n\")\n",
        "    accuracy_test, trainable_count = pp.evaluate_overall(device = \"gpu\")\n",
        "    pfile.write(\"Accuracy: {} \\nTrainable parameters: {} \\n\\n\".format(round(accuracy_test,2)*100, trainable_count) )\n",
        "    \n",
        "    pfile.write(\"Performance per class:\\n\")\n",
        "    beam_accuracy, tissue_accuracy, bone_accuracy = pp.evaluate_perclass()\n",
        "    pfile.write(\" Open beam: {} \\n Soft Tissue: {} \\n Bone: {}\\n\\n\".format(round(beam_accuracy,2)*100, round(tissue_accuracy,2)*100, round(bone_accuracy,2)*100))\n",
        "    \n",
        "    pfile.write(\"True Positives and False Positives:\\n\")\n",
        "    tp, fp = pp.tpfp()\n",
        "    pfile.write(\" TP: {} \\n FP {} \\n\\n \".format(round(tp,2)*100, round(fp,2)*100))\n",
        "    \n",
        "    pfile.write(\"Threshold 90% \\n\")\n",
        "    thresh90 = pp.thresholding(0.9)\n",
        "    tp90, fp90 = pp.tpfp(thresh90)\n",
        "    pfile.write(\" TP90: {} \\n FP90 {}\\n \\n \".format(round(tp90,2)*100, round(fp90,2)*100))\n",
        "    \n",
        "    pfile.write(\"Threshold 99% \\n\")\n",
        "    thresh99 = pp.thresholding(0.99)\n",
        "    tp99, fp99 = pp.tpfp(thresh99)\n",
        "    pfile.write(\" TP99: {} \\n FP99 {}\\n \\n \".format(round(tp99,2)*100, round(fp99,2)*100))\n",
        "    \n",
        "    pfile.close()\n",
        "   \n",
        "    lc_fig, lc_ax = pp.learning_curve(os.path.join(params[\"save_folder\"], params[\"name\"] + \".csv\"))\n",
        "    lc_fig.savefig(os.path.join(params[\"save_folder\"], \"learning_curve.png\"))\n",
        "    \n",
        "    rc_fig, rc_ax = pp.ROC_curve()\n",
        "    rc_fig.savefig( os.path.join(params[\"save_folder\"] , \"roc_curve.png\") )"
      ]
    }
  ]
}