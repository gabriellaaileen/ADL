{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UTS ADL_Running Modul.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2a5c5G8lcePHVLe/rqNrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellaaileen/ADL/blob/main/UTS%20ADL/UTS_ADL_Running_Modul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install future"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpLSNjtm6Ubd",
        "outputId": "a5f51aa2-a298-47be-f61e-1773bff1078e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "import rasterio"
      ],
      "metadata": {
        "id": "Ey0j7WOWVBjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ee49e9-a685-418e-be36-0b1e80b878e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A\n",
        "import argparse\n",
        "# C\n",
        "import cv2\n",
        "# G\n",
        "import glob\n",
        "# H\n",
        "import h5py\n",
        "# I\n",
        "import imgaug as ia\n",
        "import importlib.util\n",
        "# J\n",
        "import json\n",
        "# M\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "# N\n",
        "import numpy as np\n",
        "# O\n",
        "import os\n",
        "# P\n",
        "import pandas as pd\n",
        "# R\n",
        "import random\n",
        "import rasterio\n",
        "# S\n",
        "import scipy.misc\n",
        "import shutil\n",
        "import signal\n",
        "import sys\n",
        "# T\n",
        "import tensorflow\n",
        "import time\n",
        "# W\n",
        "import webbrowser\n",
        "\n",
        "### Keras\n",
        "from keras.layers import  * \n",
        "from keras.models import Model, Sequential, load_model as keras_load_model\n",
        "from keras.optimizers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, CSVLogger, TensorBoard, EarlyStopping\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from keras.optimizers import *\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "### Tensor\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "### Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "### Random\n",
        "from random import randint\n",
        "from random import shuffle\n",
        "### ImgAug\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug import parameters as iap\n",
        "### Others\n",
        "#from _future_ import division\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "hLkZfORP56Tn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anMIguNOUbO6",
        "outputId": "c74c891c-070e-42e8-f411-469fbf0f4311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ADL' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: 'UTS ADL'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gabriellaaileen/ADL.git\n",
        "%cd UTS ADL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ADL/UTS ADL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b04gF6eQ39vm",
        "outputId": "4c3e6cc1-2e2d-443b-a406-c28d29cb445c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ADL/UTS ADL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/generate_parameters.py\""
      ],
      "metadata": {
        "id": "VHI1QNmXU0VG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec76879-dab3-4e1f-b986-c33fb5310023"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning params file exists, continue? (y/n) y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/rgb2label.py\""
      ],
      "metadata": {
        "id": "Eat45UII9EMK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/TrainingClass.py\""
      ],
      "metadata": {
        "id": "rqmDcrKiU7mF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/PostProcessing.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynu1c3_x8yDU",
        "outputId": "f9b7822c-0437-418a-c356-4447db2bf1eb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/XNet.py\""
      ],
      "metadata": {
        "id": "c3eIQB8U9cYN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/train.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z29l_B4mVX0k",
        "outputId": "094b6977-eb24-4db0-b39b-36125ecaf111"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "I will train on all these parameter files:\n",
            "\n",
            "parameters.txt\n",
            "Warning, folder exists! Delete? (y/n) y\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ADL/UTS ADL/train.py\", line 41, in <module>\n",
            "    training = TrainingClass.TrainingClass(**params)\n",
            "  File \"/content/ADL/UTS ADL/TrainingClass.py\", line 59, in __init__\n",
            "    self.load_data()\n",
            "  File \"/content/ADL/UTS ADL/TrainingClass.py\", line 68, in load_data\n",
            "    hf = h5py.File(self.data_path, 'r')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 427, in __init__\n",
            "    swmr=swmr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 190, in make_fid\n",
            "    fid = h5f.open(name, flags, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 96, in h5py.h5f.open\n",
            "OSError: Unable to open file (unable to open file: name = 'Humans_CT_Phantom_s224.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/ADL/UTS ADL/augmentations.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTPs1DweGA1N",
        "outputId": "ef5b16e8-29b4-48aa-f8e6-52e302a9d448"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking labels and data match in Humans folder ...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ADL/UTS ADL/augmentations.py\", line 51, in <module>\n",
            "    balanced_test_val_split(main_path, data_to_add, image_size, train_size, n_classes)\n",
            "  File \"/content/ADL/UTS ADL/utils.py\", line 27, in balanced_test_val_split\n",
            "    assert len(labels) != 0\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import TrainingClass\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from PostProcessing import PostProcessing\n",
        "import glob\n",
        "import shutil\n",
        "import webbrowser\n",
        "import time\n",
        "#from Killer import GracefulKiller\n",
        "#killer = GracefulKiller()\n",
        "\n",
        "param_files = glob.glob(\"aug*.txt\")\n",
        "#param_files = glob.glob(\"parameters.txt\")\n",
        "print(\"I will train on all these parameter files:\\n\")\n",
        "print(*param_files, sep = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kILrZ9sDF30w",
        "outputId": "54b89ab9-8249-421c-cd99-93fbafb198e7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will train on all these parameter files:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Opening tensorboard... \\n\")\n",
        "#tb_url = \"http://127.0.0.1:7007/\"\n",
        "#webbrowser.open(tb_url)\n",
        "\n",
        "for file in param_files:\n",
        "    params = json.load(open(file,'r'))\n",
        "\n",
        "    save_folder = params[\"save_folder\"]\n",
        "    if(os.path.isdir(save_folder)):\n",
        "        rm_folder = input(\"Warning, folder exists! Delete? (y/n) \")\n",
        "        if(rm_folder == \"y\"):\n",
        "            shutil.rmtree(save_folder)\n",
        "        else:\n",
        "            sys.exit()\n",
        "            \n",
        "    os.mkdir(save_folder)\n",
        "    training = TrainingClass.TrainingClass(**params)"
      ],
      "metadata": {
        "id": "g17KKPfFGuBn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard stuff\n",
        "#tbdir = os.path.join(save_folder, \"tboard\")\n",
        "#os.mkdir(tbdir)\n",
        "#os.system(\"killall tensorboard\")\n",
        "#os.system(\"tensorboard --logdir=\" + tbdir + \" --port=7007 &\")\n",
        "\n",
        "try:\n",
        "  training.fit()\n",
        "except:\n",
        "  print(\"\\n Dying... \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N7JK3v-G2Ib",
        "outputId": "17321fde-f0b7-40b6-9047-b0602d2db5b8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dying... \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "    print(\"Running post training analysis...\\n\")\n",
        "        \n",
        "    h5_files = np.sort(glob.glob(os.path.join(params[\"save_folder\"], \"*.h5\")))\n",
        "    try:\n",
        "        pp = PostProcessing( h5_files[-1], params[\"data_path\"], device = \"gpu\")\n",
        "    except:\n",
        "        print(\"You haven't trained anything?\")\n",
        "        continue\n",
        "\n",
        "    pfile = open(os.path.join(params[\"save_folder\"],  \"results.txt\"), \"w\")\n",
        "    pfile.write(\"Overall perfomance: \\n\")\n",
        "    accuracy_test, trainable_count = pp.evaluate_overall(device = \"gpu\")\n",
        "    pfile.write(\"Accuracy: {} \\nTrainable parameters: {} \\n\\n\".format(round(accuracy_test,2)*100, trainable_count) )\n",
        "    \n",
        "    pfile.write(\"Performance per class:\\n\")\n",
        "    beam_accuracy, tissue_accuracy, bone_accuracy = pp.evaluate_perclass()\n",
        "    pfile.write(\" Open beam: {} \\n Soft Tissue: {} \\n Bone: {}\\n\\n\".format(round(beam_accuracy,2)*100, round(tissue_accuracy,2)*100, round(bone_accuracy,2)*100))\n",
        "    \n",
        "    pfile.write(\"True Positives and False Positives:\\n\")\n",
        "    tp, fp = pp.tpfp()\n",
        "    pfile.write(\" TP: {} \\n FP {} \\n\\n \".format(round(tp,2)*100, round(fp,2)*100))\n",
        "    \n",
        "    pfile.write(\"Threshold 90% \\n\")\n",
        "    thresh90 = pp.thresholding(0.9)\n",
        "    tp90, fp90 = pp.tpfp(thresh90)\n",
        "    pfile.write(\" TP90: {} \\n FP90 {}\\n \\n \".format(round(tp90,2)*100, round(fp90,2)*100))\n",
        "    \n",
        "    pfile.write(\"Threshold 99% \\n\")\n",
        "    thresh99 = pp.thresholding(0.99)\n",
        "    tp99, fp99 = pp.tpfp(thresh99)\n",
        "    pfile.write(\" TP99: {} \\n FP99 {}\\n \\n \".format(round(tp99,2)*100, round(fp99,2)*100))\n",
        "    \n",
        "    pfile.close()\n",
        "   \n",
        "    lc_fig, lc_ax = pp.learning_curve(os.path.join(params[\"save_folder\"], params[\"name\"] + \".csv\"))\n",
        "    lc_fig.savefig(os.path.join(params[\"save_folder\"], \"learning_curve.png\"))\n",
        "    \n",
        "    rc_fig, rc_ax = pp.ROC_curve()\n",
        "    rc_fig.savefig( os.path.join(params[\"save_folder\"] , \"roc_curve.png\") )\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "zbmVK9xc_wdw",
        "outputId": "5bea6d04-0ac5-460d-b39e-5146a47772b9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning, folder exists! Delete? (y/n) y\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-7e9a97273519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#os.system(\"killall tensorboard\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#os.system(\"tensorboard --logdir=\" + tbdir + \" --port=7007 &\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in param_files:\n",
        "    params = json.load(open(file,'r'))\n",
        "    #params[\"save_folder\"]\n",
        "\n",
        "    training = TrainingClass.TrainingClass(**params)"
      ],
      "metadata": {
        "id": "aD9qmJVBACzS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  training.fit()\n",
        "except:\n",
        "  print(\"\\n Dying... \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRuWu7kIAIWm",
        "outputId": "d6ce96b0-835d-45d6-bcc2-830192bd8b59"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dying... \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import TrainingClass\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from PostProcessing import PostProcessing\n",
        "import glob\n",
        "import shutil\n",
        "import webbrowser\n",
        "import time\n",
        "#from Killer import GracefulKiller\n",
        "#killer = GracefulKiller()\n",
        "\n",
        "param_files = glob.glob(\"aug*.txt\")\n",
        "print(\"I will train on all these parameter files:\\n\")\n",
        "print(*param_files, sep = \"\\n\")\n",
        "\n",
        "#print(\"Opening tensorboard... \\n\")\n",
        "#tb_url = \"http://127.0.0.1:7007/\"\n",
        "#webbrowser.open(tb_url)\n",
        "\n",
        "for file in param_files:\n",
        "    params = json.load(open(file,'r'))\n",
        "\n",
        "    save_folder = params[\"save_folder\"]\n",
        "    if(os.path.isdir(save_folder)):\n",
        "        rm_folder = input(\"Warning, folder exists! Delete? (y/n) \")\n",
        "        if(rm_folder == \"y\"):\n",
        "            shutil.rmtree(save_folder)\n",
        "        else:\n",
        "            sys.exit()\n",
        "            \n",
        "    os.mkdir(save_folder)\n",
        "\n",
        "    #tensorboard stuff\n",
        "    #tbdir = os.path.join(save_folder, \"tboard\")\n",
        "    #os.mkdir(tbdir)\n",
        "    #os.system(\"killall tensorboard\")\n",
        "    #os.system(\"tensorboard --logdir=\" + tbdir + \" --port=7007 &\")\n",
        "    training = TrainingClass.TrainingClass(**params)\n",
        "    try:\n",
        "        training.fit()\n",
        "    except:\n",
        "        print(\"\\n Dying... \\n\")\n",
        "        \n",
        "    print(\"Running post training analysis...\\n\")\n",
        "        \n",
        "    h5_files = np.sort(glob.glob(os.path.join(params[\"save_folder\"], \"*.h5\")))\n",
        "    try:\n",
        "        pp = PostProcessing( h5_files[-1], params[\"data_path\"], device = \"gpu\")\n",
        "    except:\n",
        "        print(\"You haven't trained anything?\")\n",
        "        continue\n",
        "\n",
        "    pfile = open(os.path.join(params[\"save_folder\"],  \"results.txt\"), \"w\")\n",
        "    pfile.write(\"Overall perfomance: \\n\")\n",
        "    accuracy_test, trainable_count = pp.evaluate_overall(device = \"gpu\")\n",
        "    pfile.write(\"Accuracy: {} \\nTrainable parameters: {} \\n\\n\".format(round(accuracy_test,2)*100, trainable_count) )\n",
        "    \n",
        "    pfile.write(\"Performance per class:\\n\")\n",
        "    beam_accuracy, tissue_accuracy, bone_accuracy = pp.evaluate_perclass()\n",
        "    pfile.write(\" Open beam: {} \\n Soft Tissue: {} \\n Bone: {}\\n\\n\".format(round(beam_accuracy,2)*100, round(tissue_accuracy,2)*100, round(bone_accuracy,2)*100))\n",
        "    \n",
        "    pfile.write(\"True Positives and False Positives:\\n\")\n",
        "    tp, fp = pp.tpfp()\n",
        "    pfile.write(\" TP: {} \\n FP {} \\n\\n \".format(round(tp,2)*100, round(fp,2)*100))\n",
        "    \n",
        "    pfile.write(\"Threshold 90% \\n\")\n",
        "    thresh90 = pp.thresholding(0.9)\n",
        "    tp90, fp90 = pp.tpfp(thresh90)\n",
        "    pfile.write(\" TP90: {} \\n FP90 {}\\n \\n \".format(round(tp90,2)*100, round(fp90,2)*100))\n",
        "    \n",
        "    pfile.write(\"Threshold 99% \\n\")\n",
        "    thresh99 = pp.thresholding(0.99)\n",
        "    tp99, fp99 = pp.tpfp(thresh99)\n",
        "    pfile.write(\" TP99: {} \\n FP99 {}\\n \\n \".format(round(tp99,2)*100, round(fp99,2)*100))\n",
        "    \n",
        "    pfile.close()\n",
        "   \n",
        "    lc_fig, lc_ax = pp.learning_curve(os.path.join(params[\"save_folder\"], params[\"name\"] + \".csv\"))\n",
        "    lc_fig.savefig(os.path.join(params[\"save_folder\"], \"learning_curve.png\"))\n",
        "    \n",
        "    rc_fig, rc_ax = pp.ROC_curve()\n",
        "    rc_fig.savefig( os.path.join(params[\"save_folder\"] , \"roc_curve.png\") )\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7GM3W5PEgMx",
        "outputId": "5c53bbe4-064d-4963-deec-2efd78133a6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will train on all these parameter files:\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1Wel_XsyE7HcEq0TkZWI61GABO4jOtj9C',\n",
        "                                    dest_path='./dataset.hdf5')\n",
        "gdd.download_file_from_google_drive(file_id='1cePD5E-T9mr5W0xPGuzEnUt8Glpvn23U',\n",
        "                                    dest_path='./model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iReRZEHbDExG",
        "outputId": "6410ac82-c4b4-4a2a-fe45-21df651c0603"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hdf5_path = \"./dataset.hdf5\" ## this is our h5 file containing training and testing data\n",
        "dataset = h5py.File(hdf5_path , 'r')\n",
        "\n",
        "classes = 3\n",
        "test_images = dataset['test_img'][:]\n",
        "print(test_images.shape)\n",
        "no_images, height, width, channels = test_images.shape\n",
        "\n",
        "\n",
        "print(dataset['test_label'][:].shape)\n",
        "test_labels =dataset['test_label'][:].reshape(-1,height*width, classes )\n",
        "print(test_labels.shape)\n",
        "dataset.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpSO6NtxDJNE",
        "outputId": "56f3f13c-cbcc-4b53-c114-d95677f06827"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22, 200, 200, 1)\n",
            "(22, 40000, 3)\n",
            "(22, 40000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.model.predict(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "6gYIu_V8DS5D",
        "outputId": "c0bb41fc-f54a-4347-b0e0-6c98db7a4e51"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5aa56dac3774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
          ]
        }
      ]
    }
  ]
}